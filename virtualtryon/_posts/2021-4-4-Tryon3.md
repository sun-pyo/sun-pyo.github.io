---
layout: post
title: Virtual Try on - 3
noindex: false
---

# Virtual Try on - 3

여러가지 Virtual Try On 모델들을 조사해본 결과 대부분의 모델이 입력으로 사람과 옷의 이미지 뿐만 아니라 Pose data, clothes mask, human parsing map 등이 필요하기 때문에 이부분을 구현하고자 한다.     


## Clothes Mask Model

먼저 clotehs mask 모델을 어떻게 구현할까 고민을 하였다. 앞서 살펴본 Down to... 모델에서는 GrabCut이라는 알고리즘을 사용하였다고 하여 실제로 GrabCut으로 해본 결과 생각보다 성능이 좋지 않았다.                       
다음으로 생각했던 것이 Image Segmentation이다. Segmentation 모델을 학습시키기 위해서는 먼저 데이터가 필요했고 옷 데이터를 얻기위해 무신사, 빈폴 등 쇼핑몰에서 크롤링을 하였다.

#### Crawling

```python
from bs4 import BeautifulSoup 
import time
import urllib.request as req
import os

num_page = 100
save_dir = "./img"
for page in range(1,num_page):
    # page 변경
    url = "https://search.musinsa.com/category/001?device=&d_cat_cd=001&brand=&rate=&page_kind=search&list_kind=big&sort=pop&sub_sort=&page={}".format(page)
    res = req.urlopen(url)

    soup = BeautifulSoup(res, "html.parser")
    # img 태그 리스트
    img_list = soup.select("div.list_img.articleImg > a > img")
    clothes_num = 1
    for img in img_list:
        # data-original = 이미지 경로
        img_url = img.attrs['data-original']
        savename = "{}/{}_page_{}clothes.png".format(save_dir, page, clothes_num);
        clothes_num += 1
        req.urlretrieve(img_url, savename)
        print(savename, "저장 완료!")
```
위 코드는 무신사 쇼핑몰에서 이미지를 크롤링하는 코드로 무신사 쇼핑몰의 상의 카테고리에서 1~99 페이지까지 약 8900개의 이미지 데이터를 수집하였다. 

```python
from bs4 import BeautifulSoup 
import time
import urllib.request as req
import os

save_dir = "./beanpole_img"

category = ['T-shirts', 'Shirts-Blouses',  'Knitwear']
dspCtgryNo = {'T-shirts' : 'SFMA41A01', 'Shirts-Blouses' : 'SFMA41A02', 'Knitwear' : 'SFMA41A03'}

for ctgry in category:
    url = "https://www.ssfshop.com/Beanpole-Ladies{}/list?dspCtgryNo={}&brandShopNo=BDMA01A02&brndShopId=BPBBF&etcCtgryNo=&ctgrySectCd=&keyword=&leftBrandNM=".format(ctgry,dspCtgryNo[ctgry])
    res = req.urlopen(url)
    soup = BeautifulSoup(res, "html.parser")
    page = soup.select(".btn_paging")
    num_page = len(page) + 1
    #print(num_page)
    for page in range(1,num_page + 1):
        # page 변경
        url = "https://www.ssfshop.com/Beanpole-Ladies/{}/list?dspCtgryNo={}&brandShopNo=BDMA01A02&brndShopId=BPBBF&currentPage={}&sortColumn=NEW_GOD_SEQ&etcCtgryNo=&leftBrandNM=&serviceType=DSP&smtFlterVal=&price=&benefit=&delivery=&lineId=&ctgrySectCd=GNRL_CTGRY&brndId=&sizeNM=&colorCd=&materNM=&cateViewOn=&cateNo=&fitPsbYn=N".format(ctgry,dspCtgryNo[ctgry], page)
        res = req.urlopen(url)

        soup = BeautifulSoup(res, "html.parser")
        # img 태그 리스트
        hover_img_list = soup.select(".hover > img")
        img_list = soup.select("#dspGood  a > img")

        clothes_num = 1
        for img in hover_img_list:
            # src = 이미지 경로
            img_url = img.attrs['src']
            savename = "{}/{}_{}_page_{}clothes_hover.png".format(save_dir, ctgry,page, clothes_num);
            req.urlretrieve(img_url, savename)
            clothes_num += 1
            print(savename, "hover_img 저장 완료!")

        clothes_num = 1
        for img in img_list:
            # src = 이미지 경로
            img_url = img.attrs['src']
            savename = "{}/{}_{}_page_{}clothes.png".format(save_dir, ctgry,page, clothes_num);
            req.urlretrieve(img_url, savename)
            clothes_num += 1
            print(savename, "img 저장 완료!")
```

유사한 방법으로 빈폴 쇼핑몰 사이트에서 T-shirts, Shirts-Blouses, Knitwear 3가지 카테고리의 이미지 데이터를 수집하였다.                       

#### Annotation
이미지를 수집하였으니 이제 학습을 위해 Annotation을 해야한다. Annotation에 사용한 Tool은 Labelme([https://github.com/wkentaro/labelme](https://github.com/wkentaro/labelme))라고 하는 도구를 사용하였다.  

Labelme를 실행하면 다음과 같이 주석을 달 수 있고                  

![labelme](\VirtualTryOn\img\labelme.png)   

Annotation 결과로 json 파일이 생성된다.           
![json](\VirtualTryOn\img\json.PNG)  

json 파일에는 주석으로 설정한 point 좌표가 저장되며 이를 mask image로 변환할 수 있다.               
![mask](\VirtualTryOn\img\mask.PNG)  