---
layout: post
title: Virtual Try on - 2
noindex: false
---

# Virtual Try on - 2


### Down to  the Last Detail Virtual Try on with Detail Carving

![Down to  the Last Detail Virtual Try on with Detail Carving](https://d3i71xaburhd42.cloudfront.net/777b6b150b89ff01dd25d21403fc97f626d67492/3-Figure2-1.png)
이 모델은 사람의 옷과 함께 포즈도 원하는 포즈로 변경시킬 수 있다.                
모델의 input data는 다음과 같다.      
1. 사람의 이미지
2. 1번의 사람 이미지에 대한 Human Parsing
3. Target Clothes image 
4. Target Clothes mask
5. Target Pose data


이 모델은 총 4가지 Network가 있다.
* Target Pose와 Target Clothes에 맞는 새로운 Human Parsing map 생성하는 GAN
* 옷을 새로운 포즈에 맞게 Warping 해주는 network
* 위 network에서 나오는 결과들로 Try On 하는 GAN
* 얼굴을 다시 보정해주는 GAN

![Down](\virtualtryon\img\down1.PNG)                  

포즈도 변경할 수 있다는 장점이 있지만 비교적 성능은 떨어진다.                

### ACGPN
![ACGPN](https://www.programmersought.com/images/910/2ec74187f36cd9c255489d0fc4eea33e.JPEG)

이 모델의 Input은 위에서 살펴본 모델과 동일하다. 대신 포즈를 변경하지 않기 때문에 Pose data는 기존 사람의 이미지를 Target으로 한다.             

ACGPN도 4가지 Network가 있다.               
* 바뀐 옷에대한 사람의 Segmentation map(옷 부분 제외, 팔, 머리 등..) 생성하는 GAN
* 바뀐 옷에대한 Mask (옷 부분만)를 생성하는 GAN
* Warping 해주는 Network
* Try On GAN

3개의 GAN 모델은 모두 Unet을 Generator로 사용하고, patch GAN을 discriminator로 사용하여 Pix2Pix 모델과 유사하지만 input에 noise를 추가한 CGAN 구조이다.