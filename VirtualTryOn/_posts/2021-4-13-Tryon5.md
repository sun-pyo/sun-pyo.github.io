---
layout: post
title: Virtual Try on - 5
noindex: false
---

# Virtual Try on - 5


### Human Parsing
이제 Human Parsing 모델을 구현해야한다. Human Parsing은 많은 사람들이 관심을 갖고 연구된 분야이기 때문에 성능 좋은 모델과 데이터셋을 쉽게 구할 수 있었다. 하지만 ACGPN에서 사용하는 Class 형태의 모델이나 데이터셋을 찾지 못했다. 그래서 기존 LIP 데이터셋을 이용해 학습한 모델을 사용하여 유사한 class를 ACGPN에서 사용하는 class 형태로 매핑시켜 모델을 사용하였다.
                     

![acgpn_human_parsing](\VirtualTryOn\img\acgpn_human_parsing.png)         


```
0             -> 0
1,2           -> 1
5, 6, 7       -> 4
18            -> 5
19            -> 6
3, 8, 10, 11  -> 7
9, 12         -> 8
16            -> 9
17            -> 10
14            -> 11
4, 13         -> 12
15            -> 13
```

### Human Pose Estimation
Human Pose Estimation Model은 OpenPose를 사용하였고 다음과 같은 json 파일 형태로 결과를 얻어낸다.              
json 파일에는 코, 어깨, 팔꿈치 등 각각의 keypoints 정보가 x,y,score 형태로 나열되어있다.             

![pose](\VirtualTryOn\img\pose.png)     


### ACGPN Test
이제 ACGPN에 입력으로 사용되는 모든 데이터를 직접 얻어낼 수 있기 때문에 실제로 ACGPN을 실행해 결과를 확인 하였다.
모델을 실행해본 결과 입력으로 넣은 이미지의 배경이 모두 사라지거나 이상해지는 것을 확인하엿고, 모델을 모두 실행한 후 배경을 다시 합성해주어 자연스러운 결과를 얻을 수 있도록 하였다.

![result1](\VirtualTryOn\img\result1.PNG)
                        

                        
또한 셀카자세, 남자 이미지, 복잡한 배경 등.. 여러가지 환경에 대해서 실행 결과를 확인해 보았다.          
![result2](\VirtualTryOn\img\result2.PNG)